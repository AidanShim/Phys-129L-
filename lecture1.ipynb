{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1 Content | 4/1/2025\n",
    "### Syllabus:\n",
    "Grading:\n",
    "\n",
    "- Lecture Participation: 10%\n",
    "- Section Participation: 10%\n",
    "- PSETS: 30%\n",
    "- Section PSETS: 30%\n",
    "- Final Project: 20%\n",
    "\n",
    "Topics:\n",
    "- Git/Github, Docker, and Bash/Bash script\n",
    "- Basics in Differential Geometry matrix, tensors, metric, dual space, generalized coordinate transformation, vector, covector, covariant derivative, parallel transport, geodesic, surface\n",
    "derivatives, first/second fundamental forms, intrinsic/extrinsic curvatures. Numerical Mesh\n",
    "generation, Convex hull, Delaunay triangulation, lifting maps.\n",
    "- Turing Machine and Computational complexity Deterministic and Non-deterministic\n",
    "Turing machines, L,NL,P,NP problems, decision problem, function problems: such as counting\n",
    "problem, search problem, optimization problem, traveling salesman problem, quantum parallelism.\n",
    "- Basics in Matrix Theory Gaussian and Gauss-Jacobi elimination, backsubstitution, pivoting, LU decomposition, Cholesky decomposition, QR decomposition, sparse matrix linear\n",
    "algebra, QR decomposition and tridiagonal forms, diagonalization of a symmetric and nonsymmetric matrix, principal axes and covariance matrix, singular value decomposition (SVD),\n",
    "normal equations, principal component analysis (PCA) and dimensionality reduction, independent component analysis (ICA)\n",
    "- Common stochastic processes and statistical distributions in physics, Concepts in\n",
    "probability and distributions, Bayesian inference and Frequentist statistics. random walk,\n",
    "Markov chain, geometric distribution, central limit theorem, Bernoulli process, binomial process, Poisson process, Lorentz (Cauchy) distribution. Bose–Einstein statistics (Bose-Einstein\n",
    "Condensation), Fermi–Dirac statistics, Maxwell–Boltzmann statistics.\n",
    "- Common distribution sampling techniques in physics, Monte Carlo methods, stochastic\n",
    "sampling, inverse transform sampling, rejection sampling, gibbs sampling, Metropolis–Hastings\n",
    "algorithm, simulated annealing, legendre transform.\n",
    "- Foundations in neural network and artificial intelligence (AI), Pytorch, backpropagation, activation, feed-forward neural network, convolutional neural network, recurrent neural\n",
    "networks, generative adversarial network, Transformer, Autoencoder neural networks.\n",
    "- Common computation techniques in physics, discrete Fourier transform, numerical integration and differentiation, Gaussian quadrature, orthogonal (Legendre) polynomials, implicit\n",
    "and explicit iterative methods for differential equations, Runge–Kutta methods, Leapfrog, symplectic integrator, (stochastic) gradient descent, explicit/implicit regularization.\n",
    "- Applications in physics, Electrostatics, Diffusion, Brownian motion, driven system, hydrodynamics, phase transitions, molecular dynamics, ab initio approaches to electronic structure,\n",
    "quantum state (density matrix) evolution, surface code, quantum master equation, numerical\n",
    "renormalization group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
